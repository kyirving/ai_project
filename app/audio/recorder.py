import sounddevice as sd
import webrtcvad
import collections
import queue
import sys
import wave
import os
import time
import threading
import numpy as np
from app.asr.whisper_client import AudioTranscriber
from app.llm.summarizer import MeetingSummarizer
from app.utils.notifier import EmailNotifier
import app.utils.config as config

class RealtimeAssistant:
    def __init__(self, transcriber, summarizer, notifier, knowledge_base=None):
        self.transcriber = transcriber
        self.summarizer = summarizer
        self.notifier = notifier
        self.knowledge_base = knowledge_base
        
        # VAD è®¾ç½®
        # sounddevice è¯»å–çš„æ˜¯ float32 æˆ– int16ï¼Œæˆ‘ä»¬éœ€è¦ int16 ç»™ webrtcvad
        self.vad = webrtcvad.Vad(3)
        self.sample_rate = 16000 
        self.frame_duration = 30  # ms
        self.frame_size = int(self.sample_rate * self.frame_duration / 1000) # samples per frame
        
        # é˜Ÿåˆ—
        self.audio_queue = queue.Queue()
        self.is_running = False
        
        # çŠ¶æ€
        self.full_transcript = []
        self.temp_filename = "temp_recording.wav"

    def audio_callback(self, indata, frames, time, status):
        """
        sounddevice çš„å›è°ƒå‡½æ•°ï¼Œå®æ—¶è·å–éŸ³é¢‘æ•°æ®
        """
        if status:
            print(status, file=sys.stderr)
        self.audio_queue.put(bytes(indata))

    def stop(self):
        """
        å¤–éƒ¨è°ƒç”¨æ­¤æ–¹æ³•åœæ­¢å½•éŸ³
        """
        print("ğŸ›‘ æ­£åœ¨åœæ­¢å½•éŸ³...")
        self.is_running = False

    def run(self):
        print("\nğŸ™ï¸  å®æ—¶ä¼šè®®åŠ©æ‰‹å·²å¯åŠ¨")
        print("æŒ‰ Ctrl+C ç»“æŸä¼šè®®å¹¶ç”Ÿæˆçºªè¦...\n")
        
        # --- è®¾å¤‡è¯Šæ–­ä¸é€‰æ‹© ---
        print("--- éŸ³é¢‘è®¾å¤‡åˆ—è¡¨ ---")
        target_device_index = None
        target_device_name = None
        
        try:
            devices = sd.query_devices()
            print(devices)
            
            # 1. å¯»æ‰¾å¤–ç½®éº¦å…‹é£ (ä¼˜å…ˆ)
            # éå†æ‰€æœ‰è®¾å¤‡ç´¢å¼•ï¼Œé¿å…è¿­ä»£å¯¹è±¡å¯èƒ½å‡ºç°çš„æ ¼å¼é—®é¢˜
            device_count = len(devices)
            for i in range(device_count):
                try:
                    dev_info = sd.query_devices(i)
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥é€šé“
                    if dev_info.get('max_input_channels', 0) > 0 or dev_info.get('maxInputChannels', 0) > 0:
                        name = dev_info['name'].lower()
                        # åŒ¹é…å¸¸è§çš„è€³æœºéº¦å…‹é£åç§°
                        if "external" in name or "å¤–ç½®" in name or "headset" in name:
                            target_device_index = i
                            target_device_name = dev_info['name']
                            print(f"\nğŸ¯ è‡ªåŠ¨æ£€æµ‹åˆ°è€³æœº/å¤–ç½®éº¦å…‹é£: {target_device_name} (Index: {i})")
                            break
                except Exception:
                    continue
            
            # 2. å¦‚æœæ²¡æ‰¾åˆ°å¤–ç½®ï¼Œå°±ç”¨é»˜è®¤
            if target_device_index is None:
                default_input = sd.query_devices(kind='input')
                target_device_index = default_input['index']
                target_device_name = default_input['name']
                print(f"\nğŸ¤ ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¾“å…¥è®¾å¤‡: {target_device_name} (Index: {target_device_index})")

            # 3. è·å–ç›®æ ‡è®¾å¤‡çš„é‡‡æ ·ç‡
            device_info = sd.query_devices(target_device_index)
            # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„å±æ€§å (default_samplerate vs defaultSampleRate)
            hw_rate = device_info.get('default_samplerate') or device_info.get('defaultSampleRate') or 48000
            hw_rate = int(hw_rate)
            print(f"   è®¾å¤‡åŸç”Ÿé‡‡æ ·ç‡: {hw_rate} Hz")
            
            # 4. è‡ªåŠ¨é€‚é…é‡‡æ ·ç‡
            # VAD æ”¯æŒ 8000, 16000, 32000, 48000
            if hw_rate in [8000, 16000, 32000, 48000]:
                self.sample_rate = hw_rate
                print(f"âœ… å®Œç¾é€‚é…: ä½¿ç”¨è®¾å¤‡åŸç”Ÿé‡‡æ ·ç‡ {self.sample_rate} Hz")
            else:
                # å¦‚æœè®¾å¤‡æ˜¯ 44100ï¼ŒVAD ä¸æ”¯æŒã€‚
                # è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»ç”¨è®¾å¤‡åŸç”Ÿçš„ 44100 å½•éŸ³ï¼Œç„¶ååœ¨å†…å­˜é‡Œé‡é‡‡æ ·åˆ° 16000 ç»™ VAD ç”¨ã€‚
                # ä½†ä¸ºäº†ä»£ç ç®€å•ï¼Œæˆ‘ä»¬å…ˆå°è¯•å¼ºåˆ¶è¯·æ±‚ 16000ï¼Œçœ‹è®¾å¤‡æ˜¯å¦æ”¯æŒé‡é‡‡æ ·ã€‚
                print(f"âš ï¸ è®¾å¤‡é‡‡æ ·ç‡ {hw_rate} Hz ä¸è¢« VAD ç›´æ¥æ”¯æŒã€‚")
                print("ğŸ”„ å°è¯•è¯·æ±‚ 16000 Hz (ä¾èµ–ç³»ç»Ÿé‡é‡‡æ ·)...")
                self.sample_rate = 16000
                
            # æ›´æ–°å¸§å¤§å°
            self.frame_size = int(self.sample_rate * self.frame_duration / 1000)
            
        except Exception as e:
            print(f"âš ï¸ è®¾å¤‡æŸ¥è¯¢/é€‚é…å¤±è´¥: {e}")
            target_device_index = None # å›é€€åˆ° None (è®© sounddevice è‡ªå·±å†³å®š)
        print("--------------------\n")

        self.is_running = True
        
        # è¯­éŸ³ç¼“å†²
        speech_buffer = collections.deque(maxlen=50)
        triggered = False
        speech_frames = []
        
        silence_threshold = 20 # ~600ms
        silence_counter = 0
        min_speech_frames = 10 # è‡³å°‘ ~300ms

        print(">>> æ­£åœ¨ç›‘å¬...")

        # æ¨¡æ‹Ÿæ¨¡å¼æ£€æŸ¥
        simulate_mic = os.getenv("SIMULATE_MIC", "false").lower() == "true"
        stream = None
        sim_thread = None

        if simulate_mic:
            print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼: è¯»å– data/test.wav ä»£æ›¿éº¦å…‹é£")
            if not os.path.exists("data/test.wav"):
                print("âŒ æ–‡ä»¶ data/test.wav ä¸å­˜åœ¨ï¼Œè¯·æ”¾å…¥ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ç”¨äºæ¨¡æ‹Ÿã€‚")
                return
            
            def simulate_input():
                try:
                    with wave.open("data/test.wav", 'rb') as wf:
                        if wf.getframerate() != self.sample_rate:
                            print(f"âŒ æ¨¡æ‹Ÿæ–‡ä»¶é‡‡æ ·ç‡å¿…é¡»æ˜¯ {self.sample_rate}Hz")
                            return
                        
                        while self.is_running:
                            data = wf.readframes(self.frame_size)
                            if len(data) == 0:
                                time.sleep(1) # æ’­æ”¾ç»“æŸ
                                break
                            self.audio_queue.put(data)
                            time.sleep(self.frame_duration / 1000)
                except Exception as e:
                    print(f"æ¨¡æ‹Ÿçº¿ç¨‹å‡ºé”™: {e}")

            sim_thread = threading.Thread(target=simulate_input)
            sim_thread.start()
        
        else:
            # çœŸå®éº¦å…‹é£æ¨¡å¼
            try:
                stream = sd.InputStream(samplerate=self.sample_rate, 
                                    blocksize=self.frame_size,
                                    device=target_device_index, # ä½¿ç”¨é€‰å®šçš„è®¾å¤‡ç´¢å¼•
                                    channels=1, 
                                    dtype='int16',
                                    callback=self.audio_callback)
                stream.start()
            except Exception as e:
                print(f"âŒ æ— æ³•å¯åŠ¨éº¦å…‹é£: {e}")
                print("ğŸ’¡ æç¤º: è¯·å°è¯•åœ¨å¤–éƒ¨ç»ˆç«¯è¿è¡Œ (source venv/bin/activate && python3 main.py)")
                print("ğŸ’¡ æˆ–è€…: åœ¨ .env è®¾ç½® SIMULATE_MIC=true ä½¿ç”¨æ–‡ä»¶æ¨¡æ‹Ÿ")
                self.is_running = False
                return

        # ä¸»å¾ªç¯
        try:
            while self.is_running:
                try:
                    # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘å—
                    chunk = self.audio_queue.get(timeout=1)
                    
                    # VAD æ£€æµ‹
                    is_speech = self.vad.is_speech(chunk, self.sample_rate)

                    if triggered:
                        speech_frames.append(chunk)
                        if not is_speech:
                            silence_counter += 1
                        else:
                            silence_counter = 0
                            
                        if silence_counter > silence_threshold:
                            triggered = False
                            # åªæœ‰å½“è¯­éŸ³é•¿åº¦è¶³å¤Ÿæ—¶æ‰å¤„ç†
                            if len(speech_frames) > min_speech_frames:
                                self._process_speech(speech_frames)
                            else:
                                print("(å¿½ç•¥è¿‡çŸ­çš„å™ªéŸ³)", end="\r")
                                
                            speech_frames = []
                            silence_counter = 0
                            print(">>> æ­£åœ¨ç›‘å¬...", end="\r")
                    else:
                        speech_buffer.append(chunk)
                        if is_speech:
                            triggered = True
                            speech_frames.extend(speech_buffer)
                            speech_buffer.clear()
                            print("ğŸ¤  æ­£åœ¨è¯´è¯...", end="\r")
                            
                except queue.Empty:
                    if not self.is_running:
                        break
                    continue

        except KeyboardInterrupt:
            print("\n\nğŸ›‘ ä¼šè®®ç»“æŸã€‚")
        except Exception as e:
            print(f"\nâŒ è¿è¡Œæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.is_running = False
            # æ¸…ç†èµ„æº
            if stream:
                try:
                    stream.stop()
                    stream.close()
                except: pass
            
            if sim_thread and sim_thread.is_alive():
                sim_thread.join(timeout=1)
            
            if os.path.exists(self.temp_filename):
                try:
                    os.remove(self.temp_filename)
                except: pass
            
            self._finish_meeting()

    def _process_speech(self, frames):
        if not frames:
            return
            
        # ä¿å­˜ä¸ºä¸´æ—¶ WAV æ–‡ä»¶
        # ä¸ºäº†è°ƒè¯•ï¼Œæˆ‘ä»¬ä¿å­˜ä¸€ä»½å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åˆ° debug ç›®å½•
        timestamp = time.strftime("%H%M%S")
        debug_filename = f"debug/speech_{timestamp}.wav"
        
        with wave.open(self.temp_filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2) # 16-bit
            wf.setframerate(self.sample_rate)
            wf.writeframes(b''.join(frames))
            
        # å¤åˆ¶ä¸€ä»½åˆ° debug
        with open(self.temp_filename, 'rb') as f_src:
            with open(debug_filename, 'wb') as f_dst:
                f_dst.write(f_src.read())
            
        # è¯†åˆ«
        try:
            print(f"ğŸ¤ æ­£åœ¨è¯†åˆ« (éŸ³é¢‘å·²ä¿å­˜è‡³ {debug_filename})...")
            text = self.transcriber.transcribe(self.temp_filename, verbose=False)
            text = text.strip()
            if text:
                print(f"ğŸ“ {text}")
                self.full_transcript.append(text)
        except Exception as e:
            print(f"è¯†åˆ«å‡ºé”™: {e}")

    def _finish_meeting(self):
        if not self.full_transcript:
            print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œæ— éœ€ç”Ÿæˆçºªè¦ã€‚")
            return

        full_text = "\n".join(self.full_transcript)
        
        timestamp = time.strftime("%Y-%m-%d-%H-%M-%S")
        transcript_path = os.path.join("output", f"realtime_{timestamp}_transcript.txt")
        os.makedirs("output", exist_ok=True)
        
        with open(transcript_path, "w", encoding="utf-8") as f:
            f.write(full_text)
        print(f"\nğŸ“„ å®Œæ•´è½¬å½•å·²ä¿å­˜: {transcript_path}")

        print("ğŸ§  æ­£åœ¨ç”Ÿæˆä¼šè®®çºªè¦...")
        try:
            summary = self.summarizer.summarize(full_text)
            summary_path = os.path.join("output", f"realtime_{timestamp}_summary.md")
            with open(summary_path, "w", encoding="utf-8") as f:
                f.write(summary)
            print(f"âœ… ä¼šè®®çºªè¦å·²ç”Ÿæˆ: {summary_path}")
            
            # å­˜å…¥çŸ¥è¯†åº“
            if self.knowledge_base:
                try:
                    self.knowledge_base.add_meeting(
                        summary=summary,
                        transcript=full_text,
                        metadata={"source": "realtime_recording", "date": timestamp}
                    )
                except Exception as e:
                    print(f"âš ï¸ å­˜å…¥çŸ¥è¯†åº“å¤±è´¥: {e}")
            
            if config.ENABLE_EMAIL_NOTIFICATION:
                self.notifier.send_summary(
                    subject=f"å®æ—¶ä¼šè®®çºªè¦ {timestamp}",
                    summary_content=summary,
                    attachment_path=summary_path
                )
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
