from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatTongyi, ChatZhipuAI
from langchain_ollama import ChatOllama
from langchain_core.prompts import PromptTemplate
import app.utils.config as config

class MeetingSummarizer:
    """
    ä½¿ç”¨ LangChain å’Œ LLM ç”Ÿæˆä¼šè®®çºªè¦çš„ç±»ã€‚
    """
    def __init__(self, provider=config.LLM_PROVIDER):
        """
        åˆå§‹åŒ–æ€»ç»“å™¨ã€‚
        
        :param provider: LLM æä¾›å•† (openai, tongyi, glm, ollama)
        """
        self.llm = self._get_llm(provider)
        self.prompt = PromptTemplate(
            input_variables=["text"],
            template="""
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¼šè®®åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹ä¼šè®®è®°å½•å¹¶æä¾›ç»“æ„åŒ–çš„çºªè¦ã€‚
            
            çºªè¦åº”åŒ…å«ï¼š
            1. ä¼šè®®ä¸»é¢˜
            2. å…³é”®ç‚¹ (é¡¹ç›®ç¬¦å·åˆ—è¡¨)
            3. å¾…åŠäº‹é¡¹ (è°éœ€è¦åšä»€ä¹ˆ)
            4. è¾¾æˆçš„å†³è®®

            ä¼šè®®è®°å½•å†…å®¹:
            {text}

            ä¼šè®®çºªè¦:
            """
        )
        
    def _get_llm(self, provider):
        """
        æ ¹æ®é…ç½®è·å– LLM å®ä¾‹ã€‚
        """
        if provider == "tongyi":
            return ChatTongyi(api_key=config.DASHSCOPE_API_KEY)
        elif provider == "glm":
            return ChatZhipuAI(
                api_key=config.ZHIPUAI_API_KEY,
                model="glm-4"
            )
        elif provider == "ollama":
            model_name = config.OLLAMA_MODEL 
            base_url = config.OLLAMA_BASE_URL
            print(f"ğŸ”„ åˆå§‹åŒ– ChatOllama: model={model_name}, base_url={base_url}")
            return ChatOllama(model=model_name, base_url=base_url)
        else:
            # é»˜è®¤ä¸º OpenAI æˆ– å…¼å®¹ API
            return ChatOpenAI(
                api_key=config.OPENAI_API_KEY,
                base_url=config.OPENAI_BASE_URL,
                model="gpt-3.5-turbo", 
                temperature=0.3
            )

    def summarize(self, text):
        """
        ç”Ÿæˆæ‘˜è¦ã€‚
        """
        print("æ­£åœ¨ç”Ÿæˆä¼šè®®çºªè¦...")
        final_prompt = self.prompt.format(text=text)
        response = self.llm.invoke(final_prompt)
        return response.content
